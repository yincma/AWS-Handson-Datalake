#!/bin/bash

# =============================================================================
# Data Lake Unified CLI - datalake command
# Version: 2.0.0
# Description: Unified management CLI using modular architecture
# =============================================================================

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../.." && pwd)"
source "$SCRIPT_DIR/../lib/common.sh"

readonly DATALAKE_CLI_VERSION="2.0.0"

# =============================================================================
# CLI Help Display
# =============================================================================

show_help() {
    cat << 'EOF'
Data Lake Unified Management CLI (v2.0.0)

Usage:
  datalake [command] [options]

Available commands:

Infrastructure Management:
  deploy [--full] [--emr] [--analytics]  Execute complete deployment
  destroy [--force] [--deep-clean]      Delete all resources
  status                                 Check system status
  validate                               Validate configuration

Module Management:
  module <action> <module_name>         Individual module operations
    - actions: validate, deploy, status, cleanup, rollback
    - modules: s3_storage, iam_roles, glue_catalog, lake_formation,
               emr_cluster, cost_monitoring, cloudtrail_logging

Data Operations:
  upload [--sample-data]                Upload sample data
  analytics                             Execute analysis jobs
  query <sql_file>                      Execute Athena queries

Monitoring & Management:
  costs                                 Cost analysis
  logs [--hours <N>]                    Display CloudTrail logs
  security                              Security analysis
  monitoring                            System monitoring

Utilities:
  config [--validate] [--export]        Configuration management
  version                              Display version
  help                                 Display this help

Examples:
  # Deploy basic infrastructure
  datalake deploy

  # Complete deployment including EMR cluster
  datalake deploy --full

  # Operate individual modules
  datalake module deploy s3_storage
  datalake module status emr_cluster

  # Cost monitoring
  datalake costs

  # Complete deletion
  datalake destroy --force --deep-clean

For detailed information, run each command with --help.
EOF
}

# =============================================================================
# Command Processing Functions
# =============================================================================

cmd_deploy() {
    print_step "Starting data lake system deployment"
    
    local full_deploy=false
    local deploy_emr=false  
    local run_analytics=false
    
    while [[ $# -gt 0 ]]; do
        case $1 in
            --full)
                full_deploy=true
                deploy_emr=true
                run_analytics=true
                shift
                ;;
            --emr)
                deploy_emr=true
                shift
                ;;
            --analytics)
                run_analytics=true
                shift
                ;;
            --help|-h)
                cat << EOF
Data Lake Deploy Command

Usage:
  datalake deploy [options]

Options:
  --full        Complete deployment including EMR cluster and analysis jobs
  --emr         Deploy EMR cluster only
  --analytics   Execute analysis jobs (EMR required)
  --help, -h    Display this help

Examples:
  datalake deploy              # Basic infrastructure only
  datalake deploy --full       # Complete deployment
  datalake deploy --emr        # Deploy with EMR
EOF
                return 0
                ;;
            *)
                print_error "Unknown option: $1"
                return 1
                ;;
        esac
    done
    
    # Load configuration
    load_config "$PROJECT_ROOT/configs/config.env"
    
    # Check if using parallel orchestrator
    local orchestrator="$PROJECT_ROOT/scripts/core/deployment/parallel_orchestrator.sh"
    if [[ -f "$orchestrator" && "$full_deploy" == "true" ]]; then
        print_info "Using parallel orchestrator for complete deployment"
        
        # Use parallel orchestrator's standard deploy command
        "$orchestrator" deploy
        
        if [[ "$run_analytics" == "true" ]]; then
            print_info "Executing analysis jobs..."
            cmd_analytics
        fi
        
        print_success "Data lake system deployment completed"
    else
        print_warning "Using legacy scripts for deployment"
        
        # Bash 3.x compatible parameter processing
        local deploy_args=""
        if [[ "$deploy_emr" == "true" ]]; then
            deploy_args="$deploy_args --with-emr"
        fi
        if [[ "$run_analytics" == "true" ]]; then
            deploy_args="$deploy_args --with-analytics"
        fi
        
        # Set environment variable to prevent recursive calls
        export CALLED_FROM_CLI=true
        
        # Execute legacy deployment script
        if [[ -n "$deploy_args" ]]; then
            "$PROJECT_ROOT/scripts/deploy-all.sh" $deploy_args
        else
            "$PROJECT_ROOT/scripts/deploy-all.sh"
        fi
    fi
}

cmd_destroy() {
    local force=false
    local deep_clean=false
    local retry_failed=false
    
    while [[ $# -gt 0 ]]; do
        case $1 in
            --force)
                force=true
                shift
                ;;
            --deep-clean)
                deep_clean=true
                shift
                ;;
            --retry-failed)
                retry_failed=true
                shift
                ;;
            --help|-h)
                cat << EOF
Data Lake Destroy Command

Usage:
  datalake destroy [options]

Options:
  --force           Execute deletion without confirmation
  --deep-clean      Delete S3 versioned objects as well
  --retry-failed    Retry failed stack deletions
  --help, -h        Display this help

Examples:
  datalake destroy                           # Normal deletion
  datalake destroy --force --deep-clean     # Complete deletion
EOF
                return 0
                ;;
            *)
                print_error "Unknown option: $1"
                return 1
                ;;
        esac
    done
    
    if [[ "$force" != "true" ]]; then
        print_warning "All data lake resources will be deleted."
        echo -n "Do you want to continue? (y/N): "
        read -r response
        if [[ ! "$response" =~ ^[Yy]$ ]]; then
            print_info "Deletion operation cancelled"
            return 0
        fi
    fi
    
    print_step "Starting data lake resource deletion"
    
    # Load configuration
    load_config "$PROJECT_ROOT/configs/config.env"
    
    # Delete modules in order (considering dependencies)
    local cleanup_modules=("emr_cluster" "cost_monitoring" "cloudtrail_logging" "lake_formation" "glue_catalog" "iam_roles" "s3_storage")
    
    for module in "${cleanup_modules[@]}"; do
        local module_script="$PROJECT_ROOT/scripts/core/*/${module}.sh"
        local found_script
        found_script=$(find "$PROJECT_ROOT/scripts/core" -name "${module}.sh" 2>/dev/null | head -1)
        
        if [[ -n "$found_script" ]]; then
            print_info "Deleting module: $module"
            "$found_script" cleanup || print_warning "Failed to delete module $module"
        fi
    done
    
    if [[ "$deep_clean" == "true" ]]; then
        # S3 deep deletion already executed in s3_storage_cleanup
        print_debug "S3 deep deletion already executed in each module's cleanup process"
    fi
    
    print_success "Data lake resource deletion completed"
}

cmd_status() {
    print_step "Data lake system status check"
    
    load_config "$PROJECT_ROOT/configs/config.env"
    
    # Check status of all modules
    local modules=("s3_storage" "iam_roles" "glue_catalog" "lake_formation" "emr_cluster" "cost_monitoring" "cloudtrail_logging")
    local healthy_modules=0
    local total_modules=${#modules[@]}
    
    for module in "${modules[@]}"; do
        local found_script
        found_script=$(find "$PROJECT_ROOT/scripts/core" -name "${module}.sh" 2>/dev/null | head -1)
        
        if [[ -n "$found_script" ]]; then
            if "$found_script" status &>/dev/null; then
                print_success "‚úÖ $module: Normal"
                ((healthy_modules++))
            else
                print_warning "‚ö†Ô∏è $module: Abnormal or not deployed"
            fi
        else
            print_error "‚ùå $module: Script not found"
        fi
    done
    
    echo
    print_info "System health: $healthy_modules/$total_modules modules are normal"
    
    if [[ $healthy_modules -eq $total_modules ]]; then
        print_success "üéâ Data lake system is fully operational"
        return 0
    else
        print_warning "‚ö†Ô∏è Some modules have issues"
        return 1
    fi
}

cmd_module() {
    local action="${1:-}"
    local module_name="${2:-}"
    
    if [[ -z "$action" || -z "$module_name" ]]; then
        print_error "Usage: datalake module <action> <module_name>"
        print_info "Actions: validate, deploy, status, cleanup, rollback"
        print_info "Modules: s3_storage, iam_roles, glue_catalog, lake_formation, emr_cluster, cost_monitoring, cloudtrail_logging"
        return 1
    fi
    
    # Search for module script
    local found_script
    found_script=$(find "$PROJECT_ROOT/scripts/core" -name "${module_name}.sh" 2>/dev/null | head -1)
    
    if [[ -n "$found_script" ]]; then
        print_info "Executing $action on $module_name module"
        "$found_script" "$action" "${@:3}"
    else
        print_error "Module $module_name not found"
        return 1
    fi
}

cmd_costs() {
    local cost_script="$PROJECT_ROOT/scripts/core/monitoring/cost_monitoring.sh"
    if [[ -f "$cost_script" ]]; then
        "$cost_script" report
    else
        print_warning "Cost monitoring module is not available"
        "$PROJECT_ROOT/scripts/cost-optimization.sh"
    fi
}

cmd_logs() {
    local hours=1
    
    while [[ $# -gt 0 ]]; do
        case $1 in
            --hours)
                hours="$2"
                shift 2
                ;;
            *)
                hours="$1"
                shift
                ;;
        esac
    done
    
    local cloudtrail_script="$PROJECT_ROOT/scripts/core/monitoring/cloudtrail_logging.sh"
    if [[ -f "$cloudtrail_script" ]]; then
        "$cloudtrail_script" logs "$hours"
    else
        print_error "CloudTrail log module is not available"
        return 1
    fi
}

cmd_security() {
    local cloudtrail_script="$PROJECT_ROOT/scripts/core/monitoring/cloudtrail_logging.sh"
    if [[ -f "$cloudtrail_script" ]]; then
        "$cloudtrail_script" security
    else
        print_error "Security analysis module is not available"
        return 1
    fi
}

cmd_analytics() {
    print_step "Executing analysis jobs"
    
    # Check EMR cluster status
    local emr_script="$PROJECT_ROOT/scripts/core/compute/emr_cluster.sh"
    if [[ -f "$emr_script" ]] && "$emr_script" status &>/dev/null; then
        "$PROJECT_ROOT/scripts/submit_pyspark_job.sh"
    else
        print_error "EMR cluster is not available. Please run 'datalake module deploy emr_cluster' first"
        return 1
    fi
}

cmd_config() {
    local validate_only=false
    local export_only=false
    
    while [[ $# -gt 0 ]]; do
        case $1 in
            --validate)
                validate_only=true
                shift
                ;;
            --export)
                export_only=true
                shift
                ;;
            *)
                print_error "Unknown option: $1"
                return 1
                ;;
        esac
    done
    
    if [[ "$validate_only" == "true" ]]; then
        "$PROJECT_ROOT/scripts/lib/config/validator.sh"
    elif [[ "$export_only" == "true" ]]; then
        "$PROJECT_ROOT/scripts/utils/export_env_template.sh"
    else
        print_info "Configuration file: $PROJECT_ROOT/configs/config.env"
        if [[ -f "$PROJECT_ROOT/configs/config.local.env" ]]; then
            print_info "Local configuration: $PROJECT_ROOT/configs/config.local.env"
        fi
        "$PROJECT_ROOT/scripts/lib/config/validator.sh"
    fi
}

cmd_version() {
    echo "datalake CLI version $DATALAKE_CLI_VERSION"
    echo "Modular architecture-based AWS data lake management tool"
}

# =============================================================================
# Main Command Processing
# =============================================================================

main() {
    # Display help if no arguments provided
    if [[ $# -eq 0 ]]; then
        show_help
        return 0
    fi
    
    local command="$1"
    shift
    
    case "$command" in
        deploy)
            cmd_deploy "$@"
            ;;
        destroy)
            cmd_destroy "$@"
            ;;
        status)
            cmd_status "$@"
            ;;
        validate)
            load_config "$PROJECT_ROOT/configs/config.env"
            "$PROJECT_ROOT/scripts/lib/config/validator.sh"
            ;;
        module)
            cmd_module "$@"
            ;;
        upload)
            print_info "Sample data upload"
            # TODO: Sample data upload functionality
            ;;
        analytics)
            cmd_analytics "$@"
            ;;
        query)
            print_info "Athena query execution"
            # TODO: Athena query execution functionality
            ;;
        costs)
            cmd_costs "$@"
            ;;
        logs)
            cmd_logs "$@"
            ;;
        security)
            cmd_security "$@"
            ;;
        monitoring)
            print_info "System monitoring dashboard"
            cmd_status
            ;;
        config)
            cmd_config "$@"
            ;;
        version)
            cmd_version
            ;;
        help|--help|-h)
            show_help
            ;;
        *)
            print_error "Unknown command: $command"
            echo
            show_help
            return 1
            ;;
    esac
}

# When script is executed directly
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi